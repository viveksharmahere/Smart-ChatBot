# -*- coding: utf-8 -*-
"""Smart ChatBot

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11v44We6hfp-Uc0ramNoCaTCfyJ0yfwmU
"""

from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
import torch
import random

# Load DialoGPT model and tokenizer
model_name = "microsoft/DialoGPT-medium"  # You can use 'small', 'medium', or 'large'
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name)

# Initialize conversation history
conversation_history = []

def chatbot_response(user_input):
    global conversation_history

    # Encode the input and conversation history
    new_user_input_ids = tokenizer.encode(user_input + tokenizer.eos_token, return_tensors="pt")
    bot_input_ids = torch.cat([torch.tensor(conversation_history), new_user_input_ids], dim=-1) if len(conversation_history) > 0 else new_user_input_ids

    # Generate response with increased diversity and creativity
    chat_history_ids = model.generate(
        bot_input_ids,
        max_length=1000,
        pad_token_id=tokenizer.eos_token_id,
        no_repeat_ngram_size=3,  # Avoid repeating phrases of 3 words or more
        temperature=0.7,  # Increase temperature for more diverse responses
        top_k=50,  # Consider top 50 most likely words
        top_p=0.95  # Nucleus sampling for more creative responses
    )

    # Decode the response and update conversation history
    response = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)

    # Limit conversation history to the last few turns to prevent getting stuck
    conversation_history = chat_history_ids[:, -100:].tolist() # keep only the last 100 tokens

    return response

# Chatbot loop

print("Smart ChatBot: Hi! I'm here to chat with you. Type 'bye' to exit.")
while True:
    user_input = input("You: ")
    if user_input.lower() in ['bye', 'exit', 'quit']:
        print("Smart ChatBot: Goodbye! Have a great day!")
        break
    response = chatbot_response(user_input)
    print(f"Smart ChatBot: {response}")

